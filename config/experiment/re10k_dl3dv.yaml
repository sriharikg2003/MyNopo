# @package _global_

defaults:
  - /dataset@_group_.re10k: re10k
  - /dataset@_group_.dl3dv: dl3dv
  - override /model/encoder: noposplat
  - override /model/encoder/backbone: croco
  - override /loss: [mse, lpips]

wandb:
  name: re10k_dl3dv
  tags: [re10k_dl3dv, 256x256]

model:
  encoder:
    gs_params_head_type: dpt_gs
    pose_free: true
    intrinsics_embed_loc: encoder
    intrinsics_embed_type: token
    # pretrained_weights: './pretrained_weights/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth'

dataset:
  re10k:
    view_sampler:
      warm_up_steps: 9375
  dl3dv:
    view_sampler:
      warm_up_steps: 9375

optimizer:
  lr: 2e-4
  warm_up_steps: 125
  backbone_lr_multiplier: 0.1

data_loader:
  train:
    batch_size: 8  # 8 for each dataset, since we have 2 datasets, the total batch size is 16

trainer:
  max_steps: 18751
  val_check_interval: 500

checkpointing:
  every_n_train_steps: 9375
